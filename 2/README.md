# README: Operaciones Avanzadas con Spark

Este documento abarca ejemplos pr치cticos de operaciones avanzadas en Apache Spark, cubriendo desde transformaciones y agregaciones en DataFrames hasta la limpieza de datos y el uso de diferentes tipos de datos. A continuaci칩n, se presenta un resumen detallado del contenido del notebook, junto con ejemplos representativos.

## Contenidos del Notebook

### 1. Introducci칩n a Operaciones con DataFrames
   Configuraci칩n inicial de un DataFrame con datos ficticios de personas para ilustrar c칩mo realizar diferentes transformaciones sobre los datos.

### 2. Transformaciones y Creaci칩n de Nuevas Columnas
   - **C치lculo de Columna `Mayor30`**: A침adir una columna que indique si la persona es mayor de 30 a침os.
   - **C치lculo de `FaltanJubilacion`**: A침adir una columna que calcule cu치ntos a침os faltan para la jubilaci칩n (suponiendo la jubilaci칩n a los 67 a침os).
   - **A침adir Columna Constante `Apellidos`**: Crear una columna con un valor constante (`XYZ`) utilizando `lit()`.
   - **Eliminaci칩n de Columnas**: Eliminar columnas innecesarias (`Mayor30` y `Apellidos`).
   - **A침adir A침o de Nacimiento**: Crear una columna (`AnyoNac`) con el a침o de nacimiento calculado a partir de la edad.
   - **A침adir Identificador Incremental**: A침adir una columna `Id` incremental utilizando `monotonically_increasing_id()`.

### 3. Limpieza de Datos con `VentasNulos.csv`
   A partir de un archivo CSV con valores nulos:
   - **Eliminar Filas con M칰ltiples Nulos**: Eliminar filas que tienen al menos 4 valores nulos.
   - **Sustituci칩n de Valores Nulos**:
     - Rellenar nombres nulos con `"Empleado"`.
     - Sustituir las ventas nulas por la media de ventas de los compa침eros, redondeado a entero.
     - Rellenar los euros nulos con el valor del compa침ero que menos ha ganado.

### 4. Lectura y Limpieza de Datos desde Archivo TSV (`movies.tsv`)
   - **Lectura de Datos TSV**: Leer datos de pel칤culas desde un archivo TSV y definir un esquema expl칤cito con `StructType`.
   - **Filtrado de Datos**: Mostrar las pel칤culas en las que ha trabajado Eddie Murphy.
   - **Operaciones de Intersecci칩n**: Mostrar los int칠rpretes que han trabajado tanto en "Superman" como en "Superman II".

## Ejemplos Sencillos

### A침adir una Columna que Indique si la Persona es Mayor de 30 A침os
```python
from pyspark.sql.functions import when

df = df.withColumn("Mayor30", when(df["Edad"] > 30, True).otherwise(False))
df.show()
```
Este ejemplo a침ade una columna que indica si la persona es mayor de 30 a침os.

### Calcular A침os Restantes para la Jubilaci칩n
```python
df = df.withColumn("FaltanJubilacion", 67 - df["Edad"])
df.show()
```
A침ade una columna que calcula cu치ntos a침os le faltan a cada persona para jubilarse (suponiendo la jubilaci칩n a los 67 a침os).

### A침adir un Identificador Incremental
```python
from pyspark.sql.functions import monotonically_increasing_id

df = df.withColumn("Id", monotonically_increasing_id())
df.show()
```
A침ade una columna `Id` con un identificador incremental 칰nico para cada fila.

### Eliminar Filas con M치s de 3 Valores Nulos
```python
df = df.dropna(thresh=3)
df.show()
```
Elimina las filas que tienen al menos 4 valores nulos, asegurando que se mantengan los registros con suficiente informaci칩n.

### Sustituir Ventas Nulas por la Media de Ventas de los Compa침eros
```python
from pyspark.sql.functions import avg

media_ventas = df.select(avg(df["Ventas"])).collect()[0][0]
df = df.fillna(int(media_ventas), subset=["Ventas"])
df.show()
```
Este ejemplo reemplaza las ventas nulas por la media de las ventas de los compa침eros, redondeada a un valor entero.

### Leer Datos de Pel칤culas desde un Archivo TSV con Esquema Personalizado
```python
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField("interprete", StringType(), True),
    StructField("pelicula", StringType(), True),
    StructField("anyo", IntegerType(), True)
])

df = (spark.read.format("csv")
      .option("delimiter", "\t")
      .option("header", "false")
      .schema(schema)
      .load("dbfs:/FileStore/shared_uploads/carlosalonsomingo@gmail.com/movies.tsv"))
df.show()
```
Define un esquema expl칤cito para leer datos de un archivo TSV y cargarlos en un DataFrame.

### Filtrar Pel칤culas de Eddie Murphy
```python
df_eddie = df.filter(df["interprete"] == "Murphy, Eddie (I)").select("pelicula")
df_eddie.show()
```
Filtra las pel칤culas en las que ha trabajado el int칠rprete Eddie Murphy.

### Mostrar Int칠rpretes que Aparecen en Ambas Pel칤culas: "Superman" y "Superman II"
```python
df_superman = df.filter(df["pelicula"] == "Superman").select("interprete")
df_superman_ii = df.filter(df["pelicula"] == "Superman II").select("interprete")

interpretes_ambas = df_superman.intersect(df_superman_ii)
interpretes_ambas.show()
```
Utiliza `intersect()` para mostrar los int칠rpretes que aparecen tanto en "Superman" como en "Superman II".

---

Este README proporciona una gu칤a exhaustiva de las operaciones realizadas en el notebook, con ejemplos pr치cticos que ilustran c칩mo trabajar con datos utilizando Apache Spark. Si necesitas m치s detalles o ejemplos adicionales, 춰no dudes en ped칤rmelo! 游땕游

